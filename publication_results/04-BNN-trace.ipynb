{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Network MCMC\n",
    "Part of the Bayesian neural networks via MCMC: a Python-based tutorial\n",
    "\n",
    "This section of the tutorial covers the development of an MCMC algorithm applied to a Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, fixed, widgets\n",
    "from tqdm import tqdm\n",
    "# visulisation function\n",
    "sys.path.append('/project')\n",
    "from functions.visualisations import (\n",
    "    histogram_trace, plot_y_timeseries, \n",
    "    plot_ycorr_scatter, boxplot_weights,\n",
    "    plot_linear_data\n",
    ")\n",
    "\n",
    "from types import MethodType\n",
    "\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/project')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class with the functions and attributes required for a neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bnn_model import NeuralNetwork\n",
    "from models.mcmc import MCMC_BNN as MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "- Load in the suspot data\n",
    "- You can also load in the other regeression datasets `Lazer` and `Energy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "name        = \"Iris\" # \"Sunspot\", \"Abalone\"\n",
    "train_data   = np.loadtxt(\"data/{}/train.txt\".format(name))\n",
    "test_data    = np.loadtxt(\"data/{}/test.txt\".format(name))\n",
    "\n",
    "print('Training data shape: {}'.format(train_data.shape))\n",
    "print('Test data shape: {}'.format(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample using MCMC\n",
    "\n",
    "- Create the MCMC loop and sample the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GR\n",
    "# n_samples = 100000 # number of samples to draw from the posterior\n",
    "# burn_in = 50000 # number of samples to discard before recording draws from the posterior\n",
    "\n",
    "# thin_factor = 10\n",
    "\n",
    "# single trace\n",
    "n_samples = 500000 # number of samples to draw from the posterior\n",
    "burn_in = 100000 # number of samples to discard before recording draws from the posterior\n",
    "hidden = 10\n",
    "learning_rate = 0.01\n",
    "thin_factor = 50\n",
    "\n",
    "# or load from sunspot data\n",
    "x_data = train_data[:,:-1]\n",
    "y_data = train_data[:,-1]\n",
    "x_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1]\n",
    "\n",
    "if name in ['Sunspot','Abalone']:\n",
    "    layer_sizes = [x_data.shape[1], hidden, 1]\n",
    "    data_case = 'regression'\n",
    "elif name in ['Iris']:\n",
    "    layer_sizes = [x_data.shape[1], hidden, 3]\n",
    "    data_case = 'classification'\n",
    "elif name in ['Ionosphere']:\n",
    "    layer_sizes = [x_data.shape[1], hidden, 2]\n",
    "    data_case = 'classification'\n",
    "else:\n",
    "    raise ValueError('data_case is invalid.')\n",
    "\n",
    "thinned_res = []\n",
    "\n",
    "## MCMC Settings and Setup\n",
    "for this_chain in np.arange(1):\n",
    "    print('Chain: {}'.format(this_chain))\n",
    "    np.random.seed(2023 + this_chain)\n",
    "    # Initialise the MCMC class\n",
    "    bnnm = NeuralNetwork(layer_sizes=layer_sizes,data_case=data_case)\n",
    "    mcmc = MCMC(bnnm,n_samples, burn_in, x_data, y_data, x_test, y_test)\n",
    "    # Run the sampler\n",
    "    results, pred = mcmc.sampler()\n",
    "    # thin to remove autocorrelation and to reduce the size of the data \n",
    "    results = results.iloc[::thin_factor,:]\n",
    "    for _ in pred.keys():\n",
    "        pred[_] = pred[_][::thin_factor,:]\n",
    "\n",
    "    thinned_res.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the predicitons into useful variables\n",
    "pred_y = pred['train_pred']\n",
    "sim_y = pred['train_sim']\n",
    "pred_y_test = pred['test_pred']\n",
    "sim_y_test = pred['test_sim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the results\n",
    "Plot the data with the mean linear fit and some uncertainty.\n",
    "\n",
    "Plot the posterior distribution and trace for each parameter using ipywidgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(results, param_name):\n",
    "    # results = results_rmse\n",
    "    posterior_mean = results[param_name].mean()\n",
    "    print('{:.3f} mean value of posterior'.format(posterior_mean))\n",
    "    histogram_trace(results[param_name].values)\n",
    "\n",
    "# use ipywidgets to get a \"gui\" dropdown to view all the parameters\n",
    "interact(\n",
    "    plot_hist, \n",
    "    results=fixed(results), \n",
    "    param_name=widgets.Dropdown(\n",
    "        options=results.columns,\n",
    "        value='w0',\n",
    "        description='Parameter:',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# Now plot posterior distribution and trace plot for selected parameters\n",
    "def plot_posterior(results_in,this_model, this_data, this_param, save_dir=None):\n",
    "    '''\n",
    "    Plot the posterior as a histogram and then the traceplot\n",
    "    '''\n",
    "    plot_data = results_in[this_param]\n",
    "    fig, ax = plt.subplots(1,1,figsize=(6,4))\n",
    "    # add light gray grid\n",
    "    ax.grid(color='xkcd:light grey',alpha=0.7)\n",
    "    # plot the posterior distribution\n",
    "    sns.histplot(plot_data.values, ax=ax, bins=20, edgecolor='xkcd:dark grey', linewidth=1.5)\n",
    "    ax.set_xlabel('Parameter Value', labelpad=10)\n",
    "    ax.set_ylabel('Frequency', labelpad=10)\n",
    "    ax.set_title('Posterior distribution', pad=10)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    \n",
    "    # plot the trace plot\n",
    "    fig1, ax1 = plt.subplots(1,1,figsize=(6,4))\n",
    "    # add light gray grid\n",
    "    ax1.grid(color='xkcd:light grey',alpha=0.7)\n",
    "    sns.lineplot(x=np.arange(plot_data.shape[0]),y=plot_data.values,ax=ax1)\n",
    "    ax1.set_xlabel('Samples', labelpad=10)\n",
    "    ax1.set_ylabel('Parameter Value', labelpad=10)\n",
    "    ax1.set_title('Trace plot', pad=10)\n",
    "\n",
    "\n",
    "    fig1.tight_layout()\n",
    "    \n",
    "    if not save_dir is None:\n",
    "        fig.savefig(os.path.join(save_dir,'{}_{}_{}_posterior.pgf'.format(this_model,this_data,this_param)))\n",
    "        fig1.savefig(os.path.join(save_dir,'{}_{}_{}_trace.pgf'.format(this_model,this_data,this_param)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join('publication_results','results')\n",
    "fig_dir = os.path.join(\n",
    "    results_dir,\n",
    "    'figures',\n",
    "    'posterior'\n",
    ")\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "plot_posterior(results,'bnn_tp',name,'b1',save_dir=fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No thinning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "name        = \"Sunspot\"\n",
    "train_data   = np.loadtxt(\"data/{}/train.txt\".format(name))\n",
    "test_data    = np.loadtxt(\"data/{}/test.txt\".format(name))\n",
    "\n",
    "print('Training data shape: {}'.format(train_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single trace\n",
    "n_samples = 25000 # number of samples to draw from the posterior\n",
    "burn_in = 5000 # number of samples to discard before recording draws from the posterior\n",
    "\n",
    "thin_factor = 1\n",
    "\n",
    "# or load from sunspot data\n",
    "x_data = train_data[:,:-1]\n",
    "y_data = train_data[:,-1]\n",
    "x_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1]\n",
    "\n",
    "if name in ['Sunspot','Abalone']:\n",
    "    layer_sizes = [x_data.shape[1], hidden, 1]\n",
    "    data_case = 'regression'\n",
    "elif name in ['Iris']:\n",
    "    layer_sizes = [x_data.shape[1], hidden, 3]\n",
    "    data_case = 'classification'\n",
    "elif name in ['Ionosphere']:\n",
    "    layer_sizes = [x_data.shape[1], hidden, 2]\n",
    "    data_case = 'classification'\n",
    "else:\n",
    "    raise ValueError('data_case is invalid.')\n",
    "\n",
    "## MCMC Settings and Setup\n",
    "np.random.seed(2023)\n",
    "# Initialise the MCMC class\n",
    "bnnm = NeuralNetwork(layer_sizes=layer_sizes,data_case=data_case)\n",
    "mcmc = MCMC(bnnm,n_samples, burn_in, x_data, y_data, x_test, y_test)\n",
    "# Run the sampler\n",
    "results_nothin, pred = mcmc.sampler()\n",
    "# thin to remove autocorrelation and to reduce the size of the data \n",
    "results_nothin = results_nothin.iloc[::thin_factor,:]\n",
    "for _ in pred.keys():\n",
    "    pred[_] = pred[_][::thin_factor,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior(results_nothin,'bnn_tp_nothinning',name,'w1',save_dir=fig_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87fbea7b3721842a93ed4da8a1ac4b18f42b1eaaedefc3a2702202c09bf233e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
