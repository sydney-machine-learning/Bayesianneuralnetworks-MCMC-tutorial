{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model MCMC\n",
    "Part of the Bayesian neural networks via MCMC: a Python-based tutorial\n",
    "\n",
    "This section of the tutorial covers the development of an MCMC algorithm applied to a simple linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, fixed, widgets\n",
    "# visulisation function\n",
    "sys.path.append('/project')\n",
    "from functions.visualisations import (\n",
    "    histogram_trace, plot_linear_data,\n",
    "    plot_y_timeseries, boxplot_weights,\n",
    "    plot_ycorr_scatter\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from types import MethodType\n",
    "\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class with the functions and attributes required for a linear model\n",
    "\n",
    "- `predict`: Function to output y given the input data and model parameters - $y = w x + b$\n",
    "- `evaluate_proposal`: Function to load a given proposal distribution ($\\theta$) and return the model prediction\n",
    "- `encode`: Helper function to encode the model parameters ($\\theta$) into the model as $w$ and $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.linear_model import LinearModel\n",
    "from models.mcmc import MCMC_Linear as MCMC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "- Load in the suspot data\n",
    "- You can also load in the other regeression datasets `Lazer` and `Energy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (105, 5)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "name        = \"Iris\"\n",
    "train_data   = np.loadtxt(\"data/{}/train.txt\".format(name))\n",
    "test_data    = np.loadtxt(\"data/{}/test.txt\".format(name))\n",
    "\n",
    "print('Training data shape: {}'.format(train_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample using MCMC\n",
    "\n",
    "- Create the MCMC loop and sample the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m mcmc \u001b[39m=\u001b[39m MCMC(lm,n_samples, burn_in, x_data, y_data, x_test, y_test)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Run the sampler\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m results, pred \u001b[39m=\u001b[39m mcmc\u001b[39m.\u001b[39;49msampler()\n\u001b[1;32m     35\u001b[0m \u001b[39m# thin to remove autocorrelation and to reduce the size of the data \u001b[39;00m\n\u001b[1;32m     36\u001b[0m results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39miloc[::thin_factor,:]\n",
      "File \u001b[0;32m/project/publication_results/models/mcmc.py:277\u001b[0m, in \u001b[0;36mMCMC_Linear.sampler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m prior_proposal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprior_likelihood(\n\u001b[1;32m    274\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma_squared, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnu_1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnu_2, theta_proposal, tausq_proposal\n\u001b[1;32m    275\u001b[0m )\n\u001b[1;32m    276\u001b[0m \u001b[39m# calculate the likelihood considering observations\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m [likelihood_proposal, pred_y[ii,], sim_y[ii,], rmse_data[ii]] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlikelihood_function(\n\u001b[1;32m    278\u001b[0m     theta_proposal, tausq_proposal\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[39m# calculate the test likelihood\u001b[39;00m\n\u001b[1;32m    282\u001b[0m [_, test_pred_y[ii,], test_sim_y[ii,], test_rmse_data[ii]] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlikelihood_function(\n\u001b[1;32m    283\u001b[0m     theta_proposal, tausq_proposal, test\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    284\u001b[0m )\n",
      "File \u001b[0;32m/project/publication_results/models/mcmc.py:144\u001b[0m, in \u001b[0;36mMCMC.classification_likelihood_function\u001b[0;34m(self, theta, tausq, test)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[39mfor\u001b[39;00m jj \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39moutput_num):\n\u001b[1;32m    143\u001b[0m         \u001b[39mif\u001b[39;00m y_data[ii] \u001b[39m==\u001b[39m jj:\n\u001b[0;32m--> 144\u001b[0m             log_likelihood \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlog(probs[ii,jj])    \n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m [log_likelihood, model_prediction, model_simulation, accuracy]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_samples = 1100000 # number of samples to draw from the posterior\n",
    "burn_in = 100000 # number of samples to discard before recording draws from the posterior\n",
    "\n",
    "thin_factor = 100\n",
    "\n",
    "# or load from sunspot data\n",
    "x_data = train_data[:,:-1]\n",
    "y_data = train_data[:,-1]\n",
    "x_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1]\n",
    "\n",
    "if name in ['Sunspot','Abalone']:\n",
    "    layer_sizes = [x_data.shape[1], 1]\n",
    "    data_case = 'regression'\n",
    "elif name in ['Iris']:\n",
    "    layer_sizes = [x_data.shape[1], 3]\n",
    "    data_case = 'classification'\n",
    "elif name in ['Ionosphere']:\n",
    "    layer_sizes = [x_data.shape[1], 2]\n",
    "    data_case = 'classification'\n",
    "else:\n",
    "    raise ValueError('data_case is invalid.')\n",
    "\n",
    "thinned_res = []\n",
    "\n",
    "## MCMC Settings and Setup\n",
    "for this_chain in np.arange(5):\n",
    "    print('Chain: {}'.format(this_chain))\n",
    "    np.random.seed(2023 + this_chain)\n",
    "    # Initialise the MCMC class\n",
    "    lm = LinearModel(layer_sizes=layer_sizes,data_case=data_case)\n",
    "    mcmc = MCMC(lm,n_samples, burn_in, x_data, y_data, x_test, y_test)\n",
    "    # Run the sampler\n",
    "    results, pred = mcmc.sampler()\n",
    "    # thin to remove autocorrelation and to reduce the size of the data \n",
    "    results = results.iloc[::thin_factor,:]\n",
    "    for _ in pred.keys():\n",
    "        pred[_] = pred[_][::thin_factor,:]\n",
    "\n",
    "    thinned_res.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the predicitons into useful variables\n",
    "pred_y = pred['train_pred']\n",
    "sim_y = pred['train_sim']\n",
    "pred_y_test = pred['test_pred']\n",
    "sim_y_test = pred['test_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thinned_res[0].shape\n",
    "\n",
    "conc_res = np.stack(thinned_res,axis=0)\n",
    "# results = pd.concat(thinned_res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conc_res.shape)\n",
    "\n",
    "from convergence.convergence import gelman_rubin\n",
    "# run gelman rubin test\n",
    "gr = gelman_rubin(conc_res)\n",
    "\n",
    "# print the results into pandas then print\n",
    "gr_df = pd.DataFrame(data = gr, index=thinned_res[0].columns).T\n",
    "gr_df.index = ['Rhat']\n",
    "gr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the results\n",
    "Plot the data with the mean linear fit and some uncertainty.\n",
    "\n",
    "Plot the posterior distribution and trace for each parameter using ipywidgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the train/test RMSE\n",
    "trainRMSE = np.array([mcmc.rmse(pred_y[_,:], y_data) for _ in np.arange(pred_y.shape[0])])\n",
    "testRMSE = np.array([mcmc.rmse(pred_y_test[_,:], y_test) for _ in np.arange(pred_y_test.shape[0])])\n",
    "\n",
    "print('Train RMSE: {:.5f} ({:.5f})'.format(trainRMSE.mean(),trainRMSE.std()))\n",
    "print('Test RMSE: {:.5f} ({:.5f})'.format(testRMSE.mean(),testRMSE.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(results, param_name):\n",
    "    # results = results_rmse\n",
    "    posterior_mean = results[param_name].mean()\n",
    "    print('{:.3f} mean value of posterior'.format(posterior_mean))\n",
    "    histogram_trace(results[param_name].values)\n",
    "\n",
    "# use ipywidgets to get a \"gui\" dropdown to view all the parameters\n",
    "interact(\n",
    "    plot_hist, \n",
    "    results=fixed(results), \n",
    "    param_name=widgets.Dropdown(\n",
    "        options=results.columns,\n",
    "        value='w0',\n",
    "        description='Parameter:',\n",
    "    )\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87fbea7b3721842a93ed4da8a1ac4b18f42b1eaaedefc3a2702202c09bf233e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
