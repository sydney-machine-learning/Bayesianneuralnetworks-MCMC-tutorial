{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic MCMC\n",
    "Part of the Bayesian neural networks via MCMC: a Python-based tutorial\n",
    "\n",
    "This section of the tutorial covers the development of a basic MCMC algorithm.\n",
    "This example takes inspiration from [this blog post](https://towardsdatascience.com/bayesian-inference-and-markov-chain-monte-carlo-sampling-in-python-bada1beabca7) with some simplifications and notation updated to align with the accompanying tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "# visulisation function\n",
    "from functions.visualisations import histogram_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the functions required for MCMC sampling\n",
    "\n",
    "We will start with the simplest example, sampling the posterior of a single parameter.\n",
    "In this example, we are trying to obtain information about the probability of success given some data of `k` successes in `n` trials using an uninformative prior.\n",
    "\n",
    "This type of problem is represented by a binomial distribution and we will be solving for the posterior distribution of parameter `p` (probability of success) in this distribution.\n",
    "\n",
    "First, we need to define the likelihood function given our data (`k`,`n`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define our likelihood function which will be dependent on provided `data`\n",
    "def generate_likelihood(k, n):\n",
    "    '''\n",
    "    Given the data of k successes in n trials, return a likelihood function which \n",
    "    evaluates the probability that a single success (p) is query_prob for any given \n",
    "    query_prob (between 0 and 1).\n",
    "    This is defined by a binomial distribution. \n",
    "    See: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html\n",
    "    '''\n",
    "    def likelihood(query_prob):\n",
    "        return stats.binom.pmf(k, n, query_prob)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample using MCMC\n",
    "\n",
    "- Create the MCMC loop and sample the posterior distribution\n",
    "- We will use an informative, uniform prior - $Pr(p) = 1$ for $p \\in [0,1]$\n",
    "- With this symmetric prior and the proposal `p` between 0 and 1, the contribution of the proposal distribution to the MH acceptance ratio is always:\n",
    "\n",
    "$$\\frac{q(x_i \\mid x')}{q(x' \\mid x_i)} = 1$$\n",
    "\n",
    "- We therefore only need to compare the likelihood of the proposed and current sample \n",
    "$$ \\frac{P(x')}{P(x_i)} = ?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MCMC Settings and Setup\n",
    "n_samples = 10000 # number of samples to draw from the posterior\n",
    "burn_in = 2500 # number of samples to discard before recording draws from the posterior\n",
    "\n",
    "# specify our `data` for this example ensuring k <= n\n",
    "binom_k = 50 # number of successes\n",
    "binom_n = 100 # in n trials\n",
    "\n",
    "x = random.uniform(0, 1) # initialise a value of x0\n",
    "count = 0 # count the number of accepted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 MCMC samples from the posterior:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 829.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# first, given the `data` provided we need to create our likelihood function\n",
    "likelihood_function = generate_likelihood(binom_k, binom_n)\n",
    "\n",
    "# create an array of NaNs to fill with our samples\n",
    "p_posterior = np.full(n_samples, np.nan) \n",
    "\n",
    "print('Generating {} MCMC samples from the posterior:'.format(n_samples))\n",
    "# now we can start the MCMC sampling loop\n",
    "for ii in tqdm(np.arange(n_samples)):\n",
    "    # Sample a value uniformly from 0 to 1 as a proposal\n",
    "    x_new = random.uniform(0, 1)\n",
    "\n",
    "    # Calculate the Metrpolis-Hastings acceptance probability based on the prior \n",
    "    # (can be ignored in this case) and likelihood\n",
    "    prior_ratio = 1 # for this simple example as discussed above\n",
    "    likelihood_ratio = likelihood_function(x_new) / likelihood_function(x)\n",
    "    alpha = np.min([1, likelihood_ratio * prior_ratio])\n",
    "\n",
    "    # Here we use a random draw from a uniform distribution between 0 and 1 as a \n",
    "    # method of accepting the new proposal with a probability of alpha\n",
    "    # (i.e., accept if u < alpha)\n",
    "    u = random.uniform(0, 1)\n",
    "    if u < alpha:\n",
    "        x = x_new # then update the current sample to the propoal for the next iteration\n",
    "        count += 1 # add to the count of accepted samples\n",
    "\n",
    "    # Store the current sample\n",
    "    p_posterior[ii] = x\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the results\n",
    "Plot the posterior distribution and trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.880 % accepted\n",
      "0.501 mean value of posterior\n"
     ]
    }
   ],
   "source": [
    "# print(results, 'results')\n",
    "per_accept = (count/n_samples)*100\n",
    "print('{:.3f} % accepted'.format(per_accept))\n",
    "posterior_mean = np.mean(p_posterior[burn_in:])\n",
    "print('{:.3f} mean value of posterior'.format(posterior_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram_trace(\n",
    "    p_posterior, \n",
    "    true_posterior = np.vstack([np.linspace(0,1,1000),likelihood_function(np.linspace(0,1,1000))]).T, \n",
    "    burn_in = burn_in,\n",
    "    title='Posterior - p',\n",
    "    param_name = 'p',\n",
    "    # fname='figures/02-Basic-MCMC'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87fbea7b3721842a93ed4da8a1ac4b18f42b1eaaedefc3a2702202c09bf233e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
